{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%autoreload` not found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from Autoencoder import *\n",
    "from dataprocess import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. 读取CSV文件并删除第一行和第一列\n",
    "# def load_data(file_path):\n",
    "#     # 读取csv，跳过第一行（header），并删除第一列（ID列）\n",
    "#     df = pd.read_csv(file_path, skiprows=1)  # 跳过第一行\n",
    "#     df = df.drop(df.columns[0], axis=1)  # 删除第一列（ID列）\n",
    "#     df = df.drop(df.columns[0], axis=1)  # 删除时间戳列\n",
    "\n",
    "#     # 将所有数据转换为浮点数，pandas会自动处理科学记数法\n",
    "#     data = df.astype(float).values\n",
    "#     return data\n",
    "\n",
    "# # 2. 将数据转换为 [N', T, 14] 的形式\n",
    "# def prepare_data(data, T):\n",
    "#     N, D = data.shape  # N是总样本数，D是特征数（14）\n",
    "#     N_prime = N // T  # 将N划分为 N' 组，每组 T 个时间步\n",
    "#     data = data[:N_prime * T].reshape(N_prime, T, D)  # 将数据整形成 [N', T, D] 维\n",
    "    \n",
    "#     # 转换为float16格式的tensor\n",
    "#     return torch.tensor(data, dtype=torch.float16)  # 或者 torch.float32 视需要而定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Encoder(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "#         super().__init__()\n",
    "#         self.encode_lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out, (hidden, _) = self.encode_lstm(x)  # 只需要最后一个隐藏状态\n",
    "#         return out, hidden\n",
    "    \n",
    "    \n",
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self, hidden_size, output_size, num_layers=1):\n",
    "#         super().__init__()\n",
    "#         self.decode_lstm = nn.LSTM(hidden_size, output_size, num_layers, batch_first=True)\n",
    "     \n",
    "#     def forward(self, x, hidden):\n",
    "#         out, _ = self.decode_lstm(x, hidden)\n",
    "#         return out\n",
    "    \n",
    "# class Autoencoder(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size):\n",
    "#         super().__init__()\n",
    "#         self.encoder = Encoder(input_size=input_size, hidden_size=hidden_size)\n",
    "#         self.decoder = Decoder(hidden_size=hidden_size, output_size=input_size)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         decoder_input, hidden = self.encoder(x)\n",
    "#         print(f\"decoder_input size:{decoder_input.shape}\",\"\\n\", f\"hidden size is:{hidden.shape}\")\n",
    "#         decode = self.decoder(decoder_input, (hidden, torch.zeros_like(hidden)))\n",
    "#         return decode\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, dataloader, num_epochs=20, lr=1e-3):\n",
    "#     criterion = nn.MSELoss()  # 重建误差损失\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         for batch in dataloader:\n",
    "#             inputs = batch[0]\n",
    "            \n",
    "#             print(inputs.shape)\n",
    "#             outputs = model(inputs)\n",
    "            \n",
    "#             loss = criterion(outputs, inputs)\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size is: torch.Size([4639, 10, 13]) \n",
      " test data size istorch.Size([515, 10, 13]) \n",
      " the data class is<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'linear'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23816\\3518383631.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"train data size is: {train_data.shape}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"test data size is{test_data.shape}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"the data class is{type(train_data)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dimension\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dimension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mencoder_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Project\\DriverPatternRecognizition\\unlabelled data\\Autoencoder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dimension, output_dimension)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dimension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_attn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEncoderAttention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dimension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dimension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dimension\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dimension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Project\\DriverPatternRecognizition\\unlabelled data\\Autoencoder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dimension)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_dimension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_attn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dimension\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_dimension\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 得到qkv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'linear'"
     ]
    }
   ],
   "source": [
    "# run to train\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "file_path = './data/VBOX.csv'\n",
    "data = load_data(file_path)\n",
    "\n",
    "# spilt the data\n",
    "train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "# set the T and process data\n",
    "T = 10  # 1s\n",
    "train_data, test_data = switch_data(train_data, T), switch_data(test_data, T)\n",
    "train_data, test_data = torch.tensor(train_data, dtype=torch.float32).to(device), torch.tensor(test_data, dtype=torch.float32).to(device)\n",
    "input_dimension = train_data.shape[-1]\n",
    "output_dimension = 6\n",
    "print(f\"train data size is: {train_data.shape}\", \"\\n\", f\"test data size is{test_data.shape}\", \"\\n\", f\"the data class is{type(train_data)}\")\n",
    "\n",
    "encoder = Encoder(input_dimension, output_dimension)\n",
    "encoder_output = encoder(train_data[0:31, :, :])\n",
    "\n",
    "\n",
    "# # 创建数据加载器\n",
    "# train_dataset = TensorDataset(train_data)\n",
    "# test_dataset = TensorDataset(test_data)\n",
    "# print(f\"train data size is: {len(train_dataset)}\", \"\\n\", f\"test data size is: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "# # 定义自动编码器模型\n",
    "# input_size = 13  # 每个时间步的特征数\n",
    "# hidden_size = 7  # 压缩后的特征维度\n",
    "# autoencoder = Autoencoder(input_size, hidden_size)\n",
    "\n",
    "# # 训练模型\n",
    "# train_model(autoencoder, train_loader, num_epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
