{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from Autoencoder import *\n",
    "from dataprocess import *\n",
    "from train import *\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size is: torch.Size([4639, 10, 13]) \n",
      " test data size istorch.Size([515, 10, 13]) \n",
      " the data class is<class 'torch.Tensor'>\n",
      "Epoch [1/50], Loss: 686310.6250\n",
      "Epoch [2/50], Loss: 657652.0625\n",
      "Epoch [3/50], Loss: 640687.0625\n",
      "Epoch [4/50], Loss: 612397.1875\n",
      "Epoch [5/50], Loss: 554529.1875\n",
      "Epoch [6/50], Loss: 511503.8750\n",
      "Epoch [7/50], Loss: 555913.9375\n",
      "Epoch [8/50], Loss: 483697.1562\n",
      "Epoch [9/50], Loss: 456572.2812\n",
      "Epoch [10/50], Loss: 503403.4375\n",
      "Epoch [11/50], Loss: 457126.8438\n",
      "Epoch [12/50], Loss: 437234.2812\n",
      "Epoch [13/50], Loss: 488285.2188\n",
      "Epoch [14/50], Loss: 436999.5000\n",
      "Epoch [15/50], Loss: 490037.9062\n",
      "Epoch [16/50], Loss: 482696.3125\n",
      "Epoch [17/50], Loss: 460934.0000\n",
      "Epoch [18/50], Loss: 513385.3750\n",
      "Epoch [19/50], Loss: 508703.7188\n",
      "Epoch [20/50], Loss: 528281.2500\n",
      "Epoch [21/50], Loss: 481858.5312\n",
      "Epoch [22/50], Loss: 463689.7188\n",
      "Epoch [23/50], Loss: 497753.2812\n",
      "Epoch [24/50], Loss: 464546.2500\n",
      "Epoch [25/50], Loss: 509119.8750\n",
      "Epoch [26/50], Loss: 507567.0312\n",
      "Epoch [27/50], Loss: 504513.6250\n",
      "Epoch [28/50], Loss: 465335.0938\n",
      "Epoch [29/50], Loss: 471368.7188\n",
      "Epoch [30/50], Loss: 440612.2812\n",
      "Epoch [31/50], Loss: 450762.2188\n",
      "Epoch [32/50], Loss: 471410.2500\n",
      "Epoch [33/50], Loss: 454819.2188\n",
      "Epoch [34/50], Loss: 436413.0625\n",
      "Epoch [35/50], Loss: 475571.4688\n",
      "Epoch [36/50], Loss: 458553.5312\n",
      "Epoch [37/50], Loss: 446779.1562\n",
      "Epoch [38/50], Loss: 447022.0000\n",
      "Epoch [39/50], Loss: 477733.4375\n",
      "Epoch [40/50], Loss: 452096.4375\n",
      "Epoch [41/50], Loss: 459200.1875\n",
      "Epoch [42/50], Loss: 495340.7188\n",
      "Epoch [43/50], Loss: 502518.4375\n",
      "Epoch [44/50], Loss: 493791.8438\n",
      "Epoch [45/50], Loss: 448942.4688\n",
      "Epoch [46/50], Loss: 442867.1875\n",
      "Epoch [47/50], Loss: 489322.1562\n",
      "Epoch [48/50], Loss: 459594.9062\n",
      "Epoch [49/50], Loss: 517934.1875\n",
      "Epoch [50/50], Loss: 421218.2812\n"
     ]
    }
   ],
   "source": [
    "# run to train\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "file_path = './data/VBOX.csv'\n",
    "data = load_data(file_path)\n",
    "\n",
    "# spilt the data\n",
    "train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "# set the T and process data\n",
    "T = 10  # 1s\n",
    "train_data, test_data = switch_data(train_data, T), switch_data(test_data, T)\n",
    "train_data, test_data = torch.tensor(train_data, dtype=torch.float32).to(device), torch.tensor(test_data, dtype=torch.float32).to(device)\n",
    "input_dimension = train_data.shape[-1]\n",
    "hidden_dimension = input_dimension // 2 - 1\n",
    "print(f\"train data size is: {train_data.shape}\", \"\\n\", f\"test data size is{test_data.shape}\", \"\\n\", f\"the data class is{type(train_data)}\")\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------\n",
    "# encoder = Encoder(input_dimension, hidden_dimension).to(device)                  \n",
    "# encoder_output = encoder(train_data[0:32, :, :])\n",
    "# print(encoder_output)\n",
    "\n",
    "# decoder = Decoder(hidden_dimension, input_dimension).to(device)\n",
    "# decoder_output = decoder(encoder_output, encoder_output, encoder_output)\n",
    "# print(f\"decoder_output size is:{decoder_output.shape}\")\n",
    "# print(decoder_output)\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = TensorDataset(train_data)\n",
    "test_dataset = TensorDataset(test_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 创建模型\n",
    "num_layers = 6\n",
    "autoencoder = AutoEncoder(input_dimension, hidden_dimension, num_layers).to(device)\n",
    "\n",
    "# 训练模型\n",
    "train_model(autoencoder, train_loader, device, num_epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
